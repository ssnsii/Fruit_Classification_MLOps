{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDoavY3Wwsrp"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy-s_isewuBJ"
      },
      "outputs": [],
      "source": [
        "# Unzip Dataset\n",
        "!rm -rf \"/content/fruits\"\n",
        "!unzip -o \"/content/drive/MyDrive/fruit_dataset.zip\" -d \"/content/fruits\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_t6aec6-VcS_"
      },
      "outputs": [],
      "source": [
        "# Upgrade pip\n",
        "!pip install --upgrade pip --quiet\n",
        "\n",
        "# Install MLflow + pyngrok\n",
        "!pip install --quiet \\\n",
        "    mlflow==2.14.3 \\\n",
        "    pyngrok==7.4.0 \\\n",
        "    \"docker<8\" \\\n",
        "    \"graphene<4\" \\\n",
        "    \"querystring-parser<2\" \\\n",
        "    \"gunicorn<23\" \\\n",
        "    \"importlib-metadata<8\" \\\n",
        "    \"packaging<25\" \\\n",
        "    \"pyarrow>=15.0.0,<19\" \\\n",
        "    \"pytz<2025\" \\\n",
        "    \"protobuf>=4.25.3,<6\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jE3Iv0ZamYDS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import mlflow\n",
        "\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "print(\"MLflow:\", mlflow.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ocF9B17wuDY"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from skimage import exposure\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, BackupAndRestore, TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from mlflow.exceptions import MlflowException\n",
        "from mlflow.models.signature import infer_signature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVn4ONv7q3zX"
      },
      "outputs": [],
      "source": [
        "# mlflow setup\n",
        "import mlflow\n",
        "import mlflow.tensorflow\n",
        "from pyngrok import ngrok\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyYrCLnj93HM"
      },
      "outputs": [],
      "source": [
        "# Create a MLflow folder inside Google Drive\n",
        "mlflow_drive_dir = \"/content/drive/MyDrive/mlflow_runs\"\n",
        "import os\n",
        "os.makedirs(mlflow_drive_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMZWrCJKCfxY"
      },
      "outputs": [],
      "source": [
        "# Enable TensorFlow autologging\n",
        "mlflow.tensorflow.autolog(log_models=True, log_datasets=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBaum-w_sob4"
      },
      "outputs": [],
      "source": [
        "# Start MLflow UI via ngrok\n",
        "\n",
        "# Authenticate ngrok in Colab\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Set ngrok authtoken\n",
        "NGROK_TOKEN = \"33P0OLhfhI2VGm3IUmIdSI7WbLk_4ZFB1QGGoPYdCZ3QZGkQ7\"\n",
        "ngrok.set_auth_token(NGROK_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wXPP5efreTa"
      },
      "outputs": [],
      "source": [
        "# Kill old MLflow if already running\n",
        "!ps aux | grep \"mlflow ui\" | grep -v grep | awk '{print $2}' | xargs -r kill -9 || echo \"No MLflow instance running\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMYSw6SsQmeP"
      },
      "outputs": [],
      "source": [
        "# Kill old tunnels\n",
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7dc3H-Urj3Q"
      },
      "outputs": [],
      "source": [
        "# Start MLflow server bound to all interfaces\n",
        "subprocess.Popen([\n",
        "    \"mlflow\", \"ui\",\n",
        "    \"--backend-store-uri\", f\"sqlite:///{mlflow_drive_dir}/mlflow.db\",\n",
        "    \"--default-artifact-root\", mlflow_drive_dir,\n",
        "    \"--host\", \"0.0.0.0\",\n",
        "    \"--port\", \"5000\"\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Do0GCvTzr3pW"
      },
      "outputs": [],
      "source": [
        "# Wait a few seconds to ensure MLflow starts\n",
        "time.sleep(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtC6tYtfbfx6"
      },
      "outputs": [],
      "source": [
        "# Point notebook to the same backend\n",
        "mlflow.set_tracking_uri(f\"http://127.0.0.1:5000\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Icl2oOIiCXtY"
      },
      "outputs": [],
      "source": [
        "# Define experiment name\n",
        "experiment_name = \"Fruit_ResNet50V2\"\n",
        "\n",
        "# Create the experiment if it doesn't exist\n",
        "if mlflow.get_experiment_by_name(experiment_name) is None:\n",
        "    mlflow.create_experiment(\n",
        "        name=experiment_name,\n",
        "        artifact_location=mlflow_drive_dir  # store artifacts (models, plots) here\n",
        "    )\n",
        "\n",
        "# Set the experiment for logging\n",
        "mlflow.set_experiment(experiment_name)\n",
        "\n",
        "print(f\"MLflow experiment '{experiment_name}' is set!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f58RgQRFCa4R"
      },
      "outputs": [],
      "source": [
        "# Retrieve experiment details\n",
        "exp = mlflow.get_experiment_by_name(experiment_name)\n",
        "print(\"Current Experiment:\")\n",
        "print(f\"  ID: {exp.experiment_id}\")\n",
        "print(f\"  Name: {exp.name}\")\n",
        "print(f\"  Artifact Location: {exp.artifact_location}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4u7XOfC-r6lj"
      },
      "outputs": [],
      "source": [
        "# Open ngrok tunnel to access MLflow UI\n",
        "mlflow_url = ngrok.connect(5000)\n",
        "print(\"MLflow Tracking UI:\", mlflow_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nITCHnwpT8Sh"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "def start_mlflow_run_auto(run_prefix=\"Run\", nested=False):\n",
        "    \"\"\"\n",
        "    Start a new MLflow run with an auto-incremented name.\n",
        "    \"\"\"\n",
        "    experiment_name = \"Fruit_ResNet50V2\"\n",
        "    mlflow.set_experiment(experiment_name)\n",
        "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
        "\n",
        "    # Use MlflowClient to fetch existing runs in the experiment\n",
        "    client = MlflowClient()\n",
        "    runs = client.search_runs([experiment.experiment_id])\n",
        "\n",
        "    run_number = len(runs) + 1\n",
        "    run_name = f\"{run_prefix}_{run_number}\"\n",
        "\n",
        "    return mlflow.start_run(run_name=run_name, experiment_id=experiment.experiment_id, nested=nested)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dCOYAIO8ISR"
      },
      "outputs": [],
      "source": [
        "# paths for the dataset\n",
        "source_dir = '/content/fruits/fruit_dataset'\n",
        "destination_dir = '/content/fruit_data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVewXtyC8hp6"
      },
      "outputs": [],
      "source": [
        "# to list all class folder names inside the dataset\n",
        "fruit_folders = sorted(os.listdir(source_dir))\n",
        "print(\"Fruit Classes:\", fruit_folders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuIX9XTt8i_W"
      },
      "outputs": [],
      "source": [
        "# Create directories and copy the relevant fruit folders\n",
        "os.makedirs(destination_dir, exist_ok=True)\n",
        "\n",
        "for folder in fruit_folders:\n",
        "    src_folder = os.path.join(source_dir, folder)\n",
        "    dst_folder = os.path.join(destination_dir, folder)\n",
        "\n",
        "    # to only copy if destination folder doesn't already exist\n",
        "    if not os.path.exists(dst_folder):\n",
        "        shutil.copytree(src_folder, dst_folder)\n",
        "\n",
        "print(\"All fruit folders copied to:\", destination_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fwenYAV8kOd"
      },
      "outputs": [],
      "source": [
        "def split_dataset(source_dir, destination_dir, train_size=0.7, val_size=0.2, test_size=0.1):\n",
        "\n",
        "    # safer check for floating-point sum\n",
        "    assert abs(train_size + val_size + test_size - 1.0) < 1e-6, \\\n",
        "           \"Train, val, and test sizes must sum to 1.\"\n",
        "\n",
        "    splits = ['train', 'val', 'test']\n",
        "    split_dirs = {split: os.path.join(destination_dir, split) for split in splits}\n",
        "\n",
        "    # Create base split directories\n",
        "    for dir_path in split_dirs.values():\n",
        "        os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "    # Iterate over classes\n",
        "    for class_name in os.listdir(source_dir):\n",
        "        class_path = os.path.join(source_dir, class_name)\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "\n",
        "        # Create class folders inside each split folder\n",
        "        for dir_path in split_dirs.values():\n",
        "            os.makedirs(os.path.join(dir_path, class_name), exist_ok=True)\n",
        "\n",
        "        # List images in class folder\n",
        "        images = os.listdir(class_path)\n",
        "\n",
        "        # Split into train and temp (val+test)\n",
        "        train_imgs, temp_imgs = train_test_split(images, train_size=train_size, random_state=42)\n",
        "\n",
        "        # Calculate relative val and test sizes\n",
        "        val_ratio = val_size / (val_size + test_size)\n",
        "\n",
        "        # Split temp into val and test\n",
        "        val_imgs, test_imgs = train_test_split(temp_imgs, test_size=1 - val_ratio, random_state=42)\n",
        "\n",
        "        # Copy images to their respective folders\n",
        "        for img_list, split in zip([train_imgs, val_imgs, test_imgs], splits):\n",
        "            for img in img_list:\n",
        "                src = os.path.join(class_path, img)\n",
        "                dst = os.path.join(split_dirs[split], class_name, img)\n",
        "                shutil.copy(src, dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djBumJK78neT"
      },
      "outputs": [],
      "source": [
        "# Splitting Dataset\n",
        "source_dir = '/content/fruit_data'           # folder with copied data\n",
        "destination_dir = '/content/fruit_split_data'  # folder where the train/val/test splits will be created\n",
        "\n",
        "split_dataset(source_dir, destination_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEnsdzOU8o85"
      },
      "outputs": [],
      "source": [
        "# Class Distribution in the train split\n",
        "split_dataset_path = '/content/fruit_split_data/train'  # the train folder path\n",
        "class_names = [folder for folder in os.listdir(split_dataset_path)\n",
        "               if os.path.isdir(os.path.join(split_dataset_path, folder))]\n",
        "\n",
        "for class_name in class_names:\n",
        "    class_path = os.path.join(split_dataset_path, class_name)\n",
        "    num_images = len(os.listdir(class_path))\n",
        "    print(f\"{class_name}: {num_images} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLDmtNAp8qNz"
      },
      "outputs": [],
      "source": [
        "# Data Generators Setup for Raw vs Ripe Fruit\n",
        "target_size = (224, 224)\n",
        "batch_size = 30\n",
        "num_classes = 22   # 11 raw + 11 ripe = 22 classes\n",
        "channels = 3\n",
        "epochs = 100\n",
        "\n",
        "# data augmentation - this helps us to increase the size of the dataset and introduce variability in the dataset.\n",
        "# data augmentation with keras by using the ImageDataGenerator class.\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=50,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=(0.4, 1.6),\n",
        "    fill_mode='nearest',\n",
        "    channel_shift_range=40.0,\n",
        "    shear_range=25.0\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    brightness_range=[0.7, 1.3]\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    brightness_range=[0.7, 1.3]\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/fruit_split_data/train',\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    '/content/fruit_split_data/val',\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/fruit_split_data/test',\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42Q-PRVu8sM_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "base_path = '/content/fruit_split_data'\n",
        "\n",
        "# Check each split directory\n",
        "for split in ['train', 'val', 'test']:\n",
        "    split_path = os.path.join(base_path, split)\n",
        "    print(f\"\\nContents of: {split_path}\")\n",
        "\n",
        "    if not os.path.exists(split_path):\n",
        "        print(f\" {split_path} does NOT exist!\")\n",
        "        continue\n",
        "\n",
        "    class_folders = [folder for folder in os.listdir(split_path)\n",
        "                     if os.path.isdir(os.path.join(split_path, folder))]\n",
        "\n",
        "    print(f\"Found {len(class_folders)} class folders.\")\n",
        "\n",
        "    for class_name in sorted(class_folders):\n",
        "        class_path = os.path.join(split_path, class_name)\n",
        "        num_images = len(os.listdir(class_path))\n",
        "        print(f\"   - {class_name}: {num_images} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0fejufX8tiT"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Compute class weights using train_generator\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_generator.classes),\n",
        "    y=train_generator.classes\n",
        ")\n",
        "\n",
        "# Convert to dictionary format\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# Print the class weights\n",
        "print(\"Class Weights per Class Index:\")\n",
        "for class_index, weight in class_weight_dict.items():\n",
        "    class_name = list(train_generator.class_indices.keys())[list(train_generator.class_indices.values()).index(class_index)]\n",
        "    print(f\"  {class_index} ({class_name}): {weight:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKY1Mqas8v6d"
      },
      "outputs": [],
      "source": [
        "class GradualUnfreezing(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, base_model, layers_per_unfreeze=5, start_epoch=3, interval=3):\n",
        "        super().__init__()\n",
        "        self.base_model = base_model\n",
        "        self.layers_per_unfreeze = layers_per_unfreeze\n",
        "        self.start_epoch = start_epoch\n",
        "        self.interval = interval\n",
        "        self.unfrozen_layers = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch >= self.start_epoch and (epoch - self.start_epoch) % self.interval == 0:\n",
        "            total_layers = len(self.base_model.layers)\n",
        "            next_unfreeze = self.unfrozen_layers + self.layers_per_unfreeze\n",
        "            if next_unfreeze <= total_layers:\n",
        "                for layer in self.base_model.layers[-next_unfreeze: -self.unfrozen_layers or None]:\n",
        "                    layer.trainable = True\n",
        "                self.unfrozen_layers = next_unfreeze\n",
        "                print(f\"\\n[Gradual Unfreezing] Unfrozen layers: last {self.unfrozen_layers} of {total_layers}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6VmmzWB8x_z"
      },
      "outputs": [],
      "source": [
        "# model architecture\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras import layers, regularizers, Model, Input\n",
        "\n",
        "def build_model(num_classes):\n",
        "    # Initialize ResNet50V2 base\n",
        "    base_model = ResNet50V2(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(224, 224, 3)\n",
        "    )\n",
        "\n",
        "    # Freeze all layers initially\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Input layer\n",
        "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "    x = base_model(inputs)\n",
        "\n",
        "    # Global pooling and dropout\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # Residual block 1\n",
        "    x1 = layers.Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(1e-5))(x)\n",
        "    x1 = layers.BatchNormalization()(x1)\n",
        "    x1 = layers.Dropout(0.3)(x1)\n",
        "    x_res = layers.Dense(1024, activation='linear')(x)\n",
        "    x = layers.Add()([x_res, x1])\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    # Residual block 2\n",
        "    x2 = layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(1e-5))(x)\n",
        "    x2 = layers.Dropout(0.3)(x2)\n",
        "    x_res2 = layers.Dense(512, activation='linear')(x)\n",
        "    x = layers.Add()([x_res2, x2])\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    # Residual block 3\n",
        "    x3 = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-5))(x)\n",
        "    x3 = layers.Dropout(0.3)(x3)\n",
        "    x_res3 = layers.Dense(256, activation='linear')(x)\n",
        "    x = layers.Add()([x_res3, x3])\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    # Final output layer\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    # Return fresh model\n",
        "    return Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19L55MLRnRSL"
      },
      "outputs": [],
      "source": [
        "base_model = ResNet50V2(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(target_size[0], target_size[1], channels)\n",
        ")\n",
        "\n",
        "model = build_model(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euMrA-1n85iE"
      },
      "outputs": [],
      "source": [
        "# Learning Rate Schedule\n",
        "\n",
        "initial_learning_rate = 1e-4\n",
        "warmup_epochs = 5\n",
        "total_epochs = epochs\n",
        "\n",
        "def warmup_cosine_decay_schedule(epoch):\n",
        "    if epoch < warmup_epochs:\n",
        "        return initial_learning_rate * ((epoch + 1) / warmup_epochs)\n",
        "    else:\n",
        "        return initial_learning_rate * (\n",
        "            0.5 * (1 + np.cos(np.pi * (epoch - warmup_epochs) / (total_epochs - warmup_epochs)))\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LrR8ukLknqW"
      },
      "outputs": [],
      "source": [
        "# Save checkpoints and backup to Google Drive\n",
        "checkpoint_dir = \"/content/drive/MyDrive/fruit_checkpoints\"\n",
        "backup_dir = \"/content/drive/MyDrive/fruit_backup\"\n",
        "tensorboard_log_dir = \"/content/drive/MyDrive/fruit_tensorboard_logs\"\n",
        "\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "os.makedirs(backup_dir, exist_ok=True)\n",
        "os.makedirs(tensorboard_log_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SxVomhw8741"
      },
      "outputs": [],
      "source": [
        "# Callbacks\n",
        "\n",
        "callbacks = [\n",
        "    # Stop training early if no improvement\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=3,\n",
        "        restore_best_weights=True,\n",
        "        min_delta=1e-4,\n",
        "        verbose=1\n",
        "    ),\n",
        "\n",
        "    # Save the best model based on validation accuracy\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=os.path.join(checkpoint_dir, 'best_fruit_model_resnet50v2.keras'),\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        save_weights_only=False,\n",
        "        mode='max',\n",
        "        verbose=1\n",
        "    ),\n",
        "\n",
        "    # Apply custom warmup and cosine decay learning rate\n",
        "    tf.keras.callbacks.LearningRateScheduler(warmup_cosine_decay_schedule),\n",
        "\n",
        "    # Gradually unfreeze base model layers\n",
        "    GradualUnfreezing(base_model),\n",
        "\n",
        "    # Automatically back up training in case of interruption\n",
        "    #tf.keras.callbacks.BackupAndRestore(backup_dir=backup_dir),\n",
        "\n",
        "    # Log training for TensorBoard visualization\n",
        "    #tf.keras.callbacks.TensorBoard(log_dir=tensorboard_log_dir, histogram_freq=1)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sa5lzYch89L1"
      },
      "outputs": [],
      "source": [
        "## 1) Manual Search - optimizer tuning\n",
        "\n",
        "# Compile Model\n",
        "\n",
        "# 1. AdamW\n",
        "#from tensorflow.keras.optimizers import AdamW\n",
        "#from tensorflow.keras.metrics import AUC, Precision, Recall\n",
        "\n",
        "# Optimizer with weight decay\n",
        "#optimizer = AdamW(\n",
        "#    learning_rate=initial_learning_rate,\n",
        "#    weight_decay=1e-4\n",
        "#)\n",
        "\n",
        "# 2. SGD (Momentum-based)\n",
        "#from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "#optimizer = SGD(\n",
        "#    learning_rate=initial_learning_rate,\n",
        "#    momentum=0.9,\n",
        "#    nesterov=True\n",
        "#)\n",
        "\n",
        "# 3. RMSprop (Hybrid adaptive)\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "optimizer = RMSprop(\n",
        "   learning_rate=initial_learning_rate,\n",
        "    rho=0.9,\n",
        "    momentum=0.9\n",
        ")\n",
        "\n",
        "# according to the plots logged and visualized in mlflow ui the RMSprop optimizer is comparatively is better because the training and validation curves are closely aligned. This indicates stable learning and\n",
        "# good generalization. no prominent overfitting or underfitting as plots obtained from training with the other optimizers.\n",
        "\n",
        "# 4. Nadam (Hybrid Adaptive)\n",
        "#from tensorflow.keras.optimizers import Nadam\n",
        "#from tensorflow.keras.metrics import AUC, Precision, Recall\n",
        "\n",
        "#optimizer = Nadam(\n",
        "#    learning_rate=initial_learning_rate,\n",
        "#   beta_1=0.9,\n",
        "#    beta_2=0.999,\n",
        "#    epsilon=1e-7\n",
        "#)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
        "    metrics=[\n",
        "        'accuracy',\n",
        "        tf.keras.metrics.AUC(name='auc'),\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall')\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96XSJhQZ8-vJ"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ewoC2vA9AFu"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "# Get class names from train_generator\n",
        "class_names = [k for k, v in sorted(train_generator.class_indices.items(), key=lambda item: item[1])]\n",
        "\n",
        "# Set up the grid with 3 rows\n",
        "n_rows = 3\n",
        "n_cols = math.ceil(len(class_names) / n_rows)\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 5 * n_rows))\n",
        "axes = axes.flatten()  # Flatten to 1D list for easy indexing\n",
        "\n",
        "# Track displayed classes\n",
        "displayed_classes = set()\n",
        "\n",
        "# Loop until we have one image per class\n",
        "while len(displayed_classes) < len(class_names):\n",
        "    images, labels = next(train_generator)\n",
        "    for i in range(len(images)):\n",
        "        label_idx = np.argmax(labels[i])\n",
        "        if label_idx not in displayed_classes:\n",
        "            axes[label_idx].imshow(images[i])\n",
        "            axes[label_idx].set_title(f\"{class_names[label_idx]}\")\n",
        "            axes[label_idx].axis('off')\n",
        "            displayed_classes.add(label_idx)\n",
        "        if len(displayed_classes) == len(class_names):\n",
        "            break\n",
        "\n",
        "# Hide any extra subplots (if total grid > number of classes)\n",
        "for j in range(len(class_names), len(axes)):\n",
        "    axes[j].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ng7pu-Zr9CqQ"
      },
      "outputs": [],
      "source": [
        "# Display 12 augmented images from the training set in a 4x4 grid with their class labels\n",
        "plt.figure(figsize=(20, 15))\n",
        "\n",
        "for i in range(12):\n",
        "    if i >= len(images):\n",
        "        break\n",
        "    ax = plt.subplot(3, 4, i + 1)  # 4 rows, 4 columns = 12 images\n",
        "    img = images[i] * 255.0\n",
        "    plt.imshow(img.astype(\"uint8\"))\n",
        "    plt.title(class_names[np.argmax(labels[i])])\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOndCKkG8BFW"
      },
      "outputs": [],
      "source": [
        "def log_custom_metrics(history, model, generator):\n",
        "    # Accuracy/Loss plots\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
        "    ax[0].plot(history.history['accuracy'], label='train_acc')\n",
        "    ax[0].plot(history.history['val_accuracy'], label='val_acc')\n",
        "    ax[0].legend(); ax[0].set_title(\"Accuracy\")\n",
        "\n",
        "    ax[1].plot(history.history['loss'], label='train_loss')\n",
        "    ax[1].plot(history.history['val_loss'], label='val_loss')\n",
        "    ax[1].legend(); ax[1].set_title(\"Loss\")\n",
        "\n",
        "    plt.savefig(\"training_curves.png\")\n",
        "    mlflow.log_artifact(\"training_curves.png\", artifact_path=\"plots\")\n",
        "    plt.close(fig)\n",
        "\n",
        "    # Predictions for Confusion Matrix\n",
        "    y_true = generator.classes\n",
        "    y_pred = np.argmax(model.predict(generator), axis=1)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=generator.class_indices.keys())\n",
        "    disp.plot(cmap=\"Blues\", xticks_rotation=45)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.savefig(\"confusion_matrix.png\")\n",
        "    mlflow.log_artifact(\"confusion_matrix.png\", artifact_path=\"plots\")\n",
        "    plt.close()\n",
        "\n",
        "    # Classification Report\n",
        "    report = classification_report(y_true, y_pred, target_names=generator.class_indices.keys())\n",
        "    with open(\"classification_report.txt\", \"w\") as f:\n",
        "        f.write(report)\n",
        "    mlflow.log_artifact(\"classification_report.txt\", artifact_path=\"reports\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2e2nKJ79EPg"
      },
      "outputs": [],
      "source": [
        "with start_mlflow_run_auto() as run:\n",
        "    # Train model\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=len(train_generator),\n",
        "        validation_data=val_generator,\n",
        "        validation_steps=len(val_generator),\n",
        "        epochs=epochs,\n",
        "        verbose=1,\n",
        "        callbacks=callbacks,\n",
        "        class_weight=class_weight_dict\n",
        "    )\n",
        "\n",
        "    # Log preprocessing and augmentation info\n",
        "    mlflow.log_param(\"normalization\", \"rescale=1./255\")\n",
        "    mlflow.log_param(\n",
        "        \"train_augmentation\",\n",
        "        \"rotation_range=50, width_shift_range=0.3, height_shift_range=0.3, zoom_range=0.3, horizontal_flip=True, brightness_range=(0.4,1.6), fill_mode='nearest', channel_shift_range=40.0, shear_range=25.0\"\n",
        "    )\n",
        "    mlflow.log_param(\"target_size\", \"(224, 224)\")\n",
        "    mlflow.log_param(\"num_classes\", 22)\n",
        "\n",
        "    # Log model architecture info\n",
        "    mlflow.log_param(\n",
        "        \"model_architecture\",\n",
        "        \"ResNet50V2 base + 3 residual dense blocks + dropout + batchnorm\"\n",
        "    )\n",
        "    mlflow.log_param(\"base_model\", \"ResNet50V2 (imagenet, include_top=False)\")\n",
        "    mlflow.log_param(\"frozen_layers\", \"All layers frozen initially\")\n",
        "    mlflow.log_param(\"activation_functions\", \"ReLU for hidden layers, Softmax for output\")\n",
        "    mlflow.log_param(\"regularization\", \"L2(1e-5)\")\n",
        "\n",
        "    # Log hyperparameters\n",
        "\n",
        "    mlflow.log_param(\"num_classes\", num_classes)\n",
        "    mlflow.log_param(\"batch_size\", batch_size)\n",
        "    mlflow.log_param(\"epochs\", epochs)\n",
        "\n",
        "    # Log optimizer details from model\n",
        "    opt_config = model.optimizer.get_config()\n",
        "    mlflow.log_param(\"optimizer\", model.optimizer.__class__.__name__)\n",
        "    for k, v in opt_config.items():\n",
        "        if isinstance(v, (dict, list)):\n",
        "            v = str(v)\n",
        "        mlflow.log_param(f\"optimizer_{k}\", v)\n",
        "\n",
        "    # Log learning rate schedule parameters\n",
        "    mlflow.log_param(\"initial_learning_rate\", initial_learning_rate)\n",
        "    mlflow.log_param(\"warmup_epochs\", warmup_epochs)\n",
        "    mlflow.log_param(\"total_epochs\", total_epochs)\n",
        "    mlflow.log_param(\"lr_schedule\", \"warmup_cosine_decay_schedule\")\n",
        "\n",
        "    # Evaluate test set\n",
        "    test_loss, test_accuracy, test_auc, test_precision, test_recall = model.evaluate(test_generator, verbose=1)\n",
        "    mlflow.log_metric(\"test_loss\", test_loss)\n",
        "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
        "    mlflow.log_metric(\"test_auc\", test_auc)\n",
        "    mlflow.log_metric(\"test_precision\", test_precision)\n",
        "    mlflow.log_metric(\"test_recall\", test_recall)\n",
        "\n",
        "    # Log artifacts (plots + metrics)\n",
        "    log_custom_metrics(history, model, test_generator)\n",
        "\n",
        "    # Log model & register in MLflow Registry\n",
        "    try:\n",
        "        mlflow.keras.log_model(\n",
        "            model,\n",
        "            artifact_path=\"fruit_classifier_model\",\n",
        "            registered_model_name=\"FruitClassifier\"\n",
        "        )\n",
        "        print(\"Model registered successfully in MLflow Model Registry!\")\n",
        "    except MlflowException as e:\n",
        "        print(\"Model registration failed:\", e)\n",
        "\n",
        "    print(\"Run completed with ID:\", run.info.run_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h12XTiaSi6Yl"
      },
      "outputs": [],
      "source": [
        "## 2.1) Grid Search - learning rate and batch size tuning\n",
        "\n",
        "# hyperparameter grid\n",
        "# RMSprop is the chosen optimizer\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "learning_rates = [1e-5, 1e-4, 1e-3]\n",
        "batch_sizes = [30, 60, 90]\n",
        "\n",
        "# Keep track of best metrics\n",
        "best_val_accuracy = 0\n",
        "best_run_id = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sc36TWCmjUPA"
      },
      "outputs": [],
      "source": [
        "# Loop through hyperparameters and log each run\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for batch in batch_sizes:\n",
        "\n",
        "        # Update train generator batch size\n",
        "        train_generator = train_datagen.flow_from_directory(\n",
        "            '/content/fruit_split_data/train',\n",
        "            target_size=target_size,\n",
        "            batch_size=batch,\n",
        "            class_mode='categorical',\n",
        "            shuffle=True,\n",
        "            seed=42\n",
        "        )\n",
        "\n",
        "        val_generator = val_datagen.flow_from_directory(\n",
        "            '/content/fruit_split_data/val',\n",
        "            target_size=target_size,\n",
        "            batch_size=batch,\n",
        "            class_mode='categorical',\n",
        "            shuffle=False\n",
        "        )\n",
        "\n",
        "        # Define optimizer with current learning rate\n",
        "        optimizer = RMSprop(\n",
        "            learning_rate=lr,\n",
        "            rho=0.9,\n",
        "            momentum=0.9\n",
        "        )\n",
        "\n",
        "        model = build_model(num_classes)\n",
        "\n",
        "        # Recompile the model\n",
        "        model.compile(\n",
        "            optimizer=optimizer,\n",
        "            loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
        "            metrics=[\n",
        "                'accuracy',\n",
        "                tf.keras.metrics.AUC(name='auc'),\n",
        "                tf.keras.metrics.Precision(name='precision'),\n",
        "                tf.keras.metrics.Recall(name='recall')\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Start a new MLflow run\n",
        "        with start_mlflow_run_auto(run_prefix=\"RMSprop_Tuning\") as run:\n",
        "\n",
        "            history = model.fit(\n",
        "                train_generator,\n",
        "                steps_per_epoch=len(train_generator),\n",
        "                validation_data=val_generator,\n",
        "                validation_steps=len(val_generator),\n",
        "                epochs=epochs,\n",
        "                verbose=1,\n",
        "                callbacks=callbacks,\n",
        "                class_weight=class_weight_dict\n",
        "            )\n",
        "\n",
        "            # Log preprocessing / augmentation info\n",
        "            mlflow.log_param(\"normalization\", \"rescale=1./255\")\n",
        "            mlflow.log_param(\n",
        "                \"train_augmentation\",\n",
        "                \"rotation_range=50, width_shift_range=0.3, height_shift_range=0.3, zoom_range=0.3, horizontal_flip=True, brightness_range=(0.4,1.6), fill_mode='nearest', channel_shift_range=40.0, shear_range=25.0\"\n",
        "            )\n",
        "            mlflow.log_param(\"target_size\", \"(224, 224)\")\n",
        "            mlflow.log_param(\"num_classes\", 22)\n",
        "\n",
        "            # Log model architecture info\n",
        "            mlflow.log_param(\n",
        "                \"model_architecture\",\n",
        "                \"ResNet50V2 base + 3 residual dense blocks + dropout + batchnorm\"\n",
        "            )\n",
        "            mlflow.log_param(\"base_model\", \"ResNet50V2 (imagenet, include_top=False)\")\n",
        "            mlflow.log_param(\"frozen_layers\", \"All layers frozen initially\")\n",
        "            mlflow.log_param(\"activation_functions\", \"ReLU for hidden layers, Softmax for output\")\n",
        "            mlflow.log_param(\"regularization\", \"L2(1e-5)\")\n",
        "\n",
        "            # Log hyperparameters\n",
        "            mlflow.log_param(\"optimizer\", \"RMSprop\")\n",
        "            mlflow.log_param(\"learning_rate\", lr)\n",
        "            mlflow.log_param(\"batch_size\", batch)\n",
        "\n",
        "            # Evaluate on test set\n",
        "            test_metrics = model.evaluate(test_generator, verbose=0)\n",
        "            metric_names = [\"loss\", \"accuracy\", \"auc\", \"precision\", \"recall\"]\n",
        "            for name, value in zip(metric_names, test_metrics):\n",
        "                mlflow.log_metric(f\"test_{name}\", value)\n",
        "\n",
        "            # Log model and artifacts\n",
        "            log_custom_metrics(history, model, test_generator)\n",
        "            mlflow.keras.log_model(model, artifact_path=\"fruit_classifier_model\")\n",
        "\n",
        "            # Track best validation accuracy ( when logged val_accuracy comes from Keras during training, while MLflow recalculates validation_accuracy\n",
        "            # afterward on the full validation set, causing slight differences.)\n",
        "            val_acc = max(history.history['val_accuracy'])\n",
        "            if val_acc > best_val_accuracy:\n",
        "                best_val_accuracy = val_acc\n",
        "                best_run_id = run.info.run_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnjnLcp229LV"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "from mlflow.tracking import MlflowClient\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McyqB24B1iqL"
      },
      "outputs": [],
      "source": [
        "# function to train and log runs for random search and Bayesian optimization\n",
        "def train_and_log_run(lr, batch_size, run_prefix=\"Run\"):\n",
        "\n",
        "    # End any leftover active run\n",
        "    if mlflow.active_run() is not None:\n",
        "        mlflow.end_run()\n",
        "\n",
        "    # Initialize tracking variables inside the function\n",
        "    best_val_accuracy = -float(\"inf\")\n",
        "    best_run_id = None\n",
        "\n",
        "    # Create data generators\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/fruit_split_data/train',\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True,\n",
        "        seed=42\n",
        "    )\n",
        "    val_generator = val_datagen.flow_from_directory(\n",
        "        '/content/fruit_split_data/val',\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # Build and compile model\n",
        "    optimizer = RMSprop(learning_rate=lr, rho=0.9, momentum=0.9)\n",
        "    model = build_model(num_classes)\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            tf.keras.metrics.AUC(name='auc'),\n",
        "            tf.keras.metrics.Precision(name='precision'),\n",
        "            tf.keras.metrics.Recall(name='recall')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Start MLflow run\n",
        "    with start_mlflow_run_auto(run_prefix=run_prefix, nested=True) as run:\n",
        "        history = model.fit(\n",
        "            train_generator,\n",
        "            steps_per_epoch=len(train_generator),\n",
        "            validation_data=val_generator,\n",
        "            validation_steps=len(val_generator),\n",
        "            epochs=epochs,\n",
        "            verbose=1,\n",
        "            callbacks=callbacks,\n",
        "            class_weight=class_weight_dict\n",
        "        )\n",
        "\n",
        "        # Log hyperparameters\n",
        "        mlflow.log_param(\"optimizer\", \"RMSprop\")\n",
        "        mlflow.log_param(\"learning_rate\", lr)\n",
        "        mlflow.log_param(\"batch_size\", batch_size)\n",
        "\n",
        "        # Log preprocessing and augmentation info\n",
        "        mlflow.log_param(\"normalization\", \"rescale=1./255\")\n",
        "        mlflow.log_param(\n",
        "            \"train_augmentation\",\n",
        "            \"rotation_range=50, width_shift_range=0.3, height_shift_range=0.3, zoom_range=0.3, horizontal_flip=True, brightness_range=(0.4,1.6), fill_mode='nearest', channel_shift_range=40.0, shear_range=25.0\"\n",
        "        )\n",
        "        mlflow.log_param(\"target_size\", \"(224, 224)\")\n",
        "        mlflow.log_param(\"num_classes\", 22)\n",
        "\n",
        "        # Log model architecture info\n",
        "        mlflow.log_param(\n",
        "            \"model_architecture\",\n",
        "            \"ResNet50V2 base + 3 residual dense blocks + dropout + batchnorm\"\n",
        "        )\n",
        "        mlflow.log_param(\"base_model\", \"ResNet50V2 (imagenet, include_top=False)\")\n",
        "        mlflow.log_param(\"frozen_layers\", \"All layers frozen initially\")\n",
        "        mlflow.log_param(\"activation_functions\", \"ReLU for hidden layers, Softmax for output\")\n",
        "        mlflow.log_param(\"regularization\", \"L2(1e-5)\")\n",
        "\n",
        "        # Evaluate test set\n",
        "        test_metrics = model.evaluate(test_generator, verbose=0)\n",
        "        metric_names = [\"loss\", \"accuracy\", \"auc\", \"precision\", \"recall\"]\n",
        "        for name, value in zip(metric_names, test_metrics):\n",
        "            mlflow.log_metric(f\"test_{name}\", value)\n",
        "\n",
        "        # Log artifacts and history plots\n",
        "        log_custom_metrics(history, model, test_generator)\n",
        "\n",
        "        # Track best validation accuracy\n",
        "        val_acc = max(history.history['val_accuracy'])\n",
        "        if val_acc > best_val_accuracy:\n",
        "            best_val_accuracy = val_acc\n",
        "            best_run_id = run.info.run_id\n",
        "\n",
        "        # Log best val accuracy for this run\n",
        "        mlflow.log_metric(\"best_val_accuracy\", best_val_accuracy)\n",
        "\n",
        "        mlflow.keras.log_model(model, artifact_path=f\"fruit_classifier_model_{best_run_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrjXNOCYtps1"
      },
      "outputs": [],
      "source": [
        "## 2.2) Random Search - learning rate and batch size tuning\n",
        "\n",
        "random_runs = []\n",
        "for _ in range(9):  # 9 random trials\n",
        "    lr = 10 ** random.uniform(-5, -2)  # 1e-5 to 1e-2\n",
        "    bs = random.choice([30, 60, 90, 120])\n",
        "    run_info = train_and_log_run(lr, bs, run_prefix=\"Random\")\n",
        "    random_runs.append(run_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dt-0fxpQ2u9-"
      },
      "outputs": [],
      "source": [
        "## 2.3) Bayesian Optimization - learning rate and batch size tuning\n",
        "bayesian_runs = []\n",
        "lr_candidates = [1e-4, 3e-4, 5e-4] # 9 times\n",
        "batch_candidates = [30, 60, 90]\n",
        "\n",
        "for lr in lr_candidates:\n",
        "    for bs in batch_candidates:\n",
        "        run_info = train_and_log_run(lr, bs, run_prefix=\"Bayesian\")\n",
        "        bayesian_runs.append(run_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1d3S07k8ksr"
      },
      "outputs": [],
      "source": [
        "# function to compute overfit and and score\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "def compute_overfit_and_score(runs, name_prefix=None):\n",
        "    \"\"\"\n",
        "    Compute overfit gap and composite score for existing MLflow runs.\n",
        "    Optionally filter by run_name prefix (e.g., 'RMSprop_Tuning', 'Random', 'Bayesian').\n",
        "\n",
        "    Args:\n",
        "        runs: list of MLflow run objects\n",
        "        name_prefix: string, if provided, only include runs whose run_name starts with this prefix\n",
        "\n",
        "    Returns:\n",
        "        list of dicts with 'run_id', 'train_acc', 'val_acc', 'val_auc', 'overfit_gap', 'score'\n",
        "    \"\"\"\n",
        "    processed_runs = []\n",
        "\n",
        "    for run in runs:\n",
        "        if name_prefix and not run.info.run_name.startswith(name_prefix):\n",
        "            continue  # skip runs not matching the prefix\n",
        "\n",
        "        metrics = run.data.metrics\n",
        "        train_acc = metrics.get(\"accuracy\", 0)\n",
        "        val_acc = metrics.get(\"val_accuracy\", 0)\n",
        "        val_auc = metrics.get(\"val_auc\", 0)\n",
        "\n",
        "        overfit_gap = train_acc - val_acc\n",
        "        score = val_acc + val_auc\n",
        "\n",
        "        processed_runs.append({\n",
        "            \"run_id\": run.info.run_id,\n",
        "            \"run_name\": run.info.run_name,\n",
        "            \"train_acc\": train_acc,\n",
        "            \"val_acc\": val_acc,\n",
        "            \"val_auc\": val_auc,\n",
        "            \"overfit_gap\": overfit_gap,\n",
        "            \"score\": score\n",
        "        })\n",
        "    return processed_runs\n",
        "\n",
        "# Fetch all runs from the experiment\n",
        "client = MlflowClient()\n",
        "experiment_name = \"Fruit_ResNet50V2\"\n",
        "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
        "all_runs = client.search_runs([experiment.experiment_id])\n",
        "\n",
        "# Filter & compute overfit/score per method\n",
        "grid_runs = compute_overfit_and_score(all_runs, name_prefix=\"RMSprop_Tuning\")\n",
        "random_runs = compute_overfit_and_score(all_runs, name_prefix=\"Random\")\n",
        "bayesian_runs = compute_overfit_and_score(all_runs, name_prefix=\"Bayesian\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IG6kG20GwMik"
      },
      "outputs": [],
      "source": [
        "def get_top_runs(runs, top_n=5):\n",
        "    \"\"\"\n",
        "    Select top runs that balance generalization (small |overfit_gap|) and good validation performance.\n",
        "\n",
        "    Args:\n",
        "        runs (list): List of dicts with keys 'overfit_gap' and 'score'\n",
        "        top_n (int): Number of top runs to return\n",
        "\n",
        "    Returns:\n",
        "        list: Top N runs sorted by (|overfit_gap| ascending, score descending)\n",
        "    \"\"\"\n",
        "    if not runs:\n",
        "        return []\n",
        "\n",
        "    # Sort by smallest absolute overfit gap (avoiding both overfit and underfit)\n",
        "    # and highest composite score (val_acc + val_auc)\n",
        "    sorted_runs = sorted(runs, key=lambda x: (abs(x[\"overfit_gap\"]), -x[\"score\"]))\n",
        "    return sorted_runs[:top_n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVg04GJI2vBY"
      },
      "outputs": [],
      "source": [
        "# Top 5 selection per method\n",
        "\n",
        "top_grid = get_top_runs(grid_runs)\n",
        "top_random = get_top_runs(random_runs)\n",
        "top_bayesian = get_top_runs(bayesian_runs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fIcP1dp9vVj"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "def plot_runs(top_runs, method_name=\"Method\"):\n",
        "    client = MlflowClient()\n",
        "\n",
        "    for i, run_info in enumerate(top_runs):\n",
        "        run_id = run_info[\"run_id\"]\n",
        "        run_name = run_info.get(\"run_name\", run_id)\n",
        "\n",
        "        # Retrieve per-epoch metric history\n",
        "        def fetch_metric_series(metric_key):\n",
        "            try:\n",
        "                history = client.get_metric_history(run_id, metric_key)\n",
        "                return [m.value for m in history]\n",
        "            except Exception:\n",
        "                return []\n",
        "\n",
        "        train_acc = fetch_metric_series(\"accuracy\")\n",
        "        val_acc = fetch_metric_series(\"val_accuracy\")\n",
        "        train_loss = fetch_metric_series(\"loss\")\n",
        "        val_loss = fetch_metric_series(\"val_loss\")\n",
        "\n",
        "        # Plot Accuracy\n",
        "        if train_acc and val_acc:\n",
        "            plt.figure(figsize=(6, 4))\n",
        "            plt.plot(train_acc, label=\"Train Accuracy\")\n",
        "            plt.plot(val_acc, label=\"Validation Accuracy\")\n",
        "            plt.title(f\"{method_name} Top Run {i+1}: {run_name}  Accuracy\")\n",
        "            plt.xlabel(\"Epoch\")\n",
        "            plt.ylabel(\"Accuracy\")\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "        # Plot Loss\n",
        "        if train_loss and val_loss:\n",
        "            plt.figure(figsize=(6, 4))\n",
        "            plt.plot(train_loss, label=\"Train Loss\")\n",
        "            plt.plot(val_loss, label=\"Validation Loss\")\n",
        "            plt.title(f\"{method_name} Top Run {i+1}: {run_name}  Loss\")\n",
        "            plt.xlabel(\"Epoch\")\n",
        "            plt.ylabel(\"Loss\")\n",
        "            plt.legend()\n",
        "            plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fIAFk8Y2vDX"
      },
      "outputs": [],
      "source": [
        "# Plot top runs\n",
        "plot_runs(top_grid, \"GridSearch\")\n",
        "plot_runs(top_random, \"RandomSearch\")\n",
        "plot_runs(top_bayesian, \"BayesianSearch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uF4FGZf-I78"
      },
      "outputs": [],
      "source": [
        "# Compare overall best\n",
        "all_top = top_grid + top_random + top_bayesian\n",
        "overall_best = sorted(all_top, key=lambda x: (x[\"overfit_gap\"], -x[\"score\"]))[0]\n",
        "best_run_id = overall_best[\"run_id\"]\n",
        "best_method = \"GridSearch\" if overall_best in top_grid else \"RandomSearch\" if overall_best in top_random else \"BayesianSearch\"\n",
        "print(f\"Overall best run: {best_run_id} from {best_method}\")\n",
        "import mlflow\n",
        "\n",
        "# Fetch run metadata\n",
        "best_run = mlflow.get_run(best_run_id)\n",
        "best_run_name = best_run.info.run_name\n",
        "\n",
        "print(f\"Overall best run: {best_run_id} ({best_run_name}) from {best_method}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLvCKv9i-I-6"
      },
      "outputs": [],
      "source": [
        "# Register & promote\n",
        "\n",
        "from mlflow.tracking import MlflowClient\n",
        "from mlflow.exceptions import MlflowException\n",
        "import mlflow\n",
        "\n",
        "client = MlflowClient()\n",
        "\n",
        "# Best run info\n",
        "best_run_id = \"0f2f64255e4946808e7f2fe71575bdb1\"\n",
        "best_run_name = mlflow.get_run(best_run_id).info.run_name  # \"Bayesian_26\"\n",
        "\n",
        "# Generate model registry name\n",
        "model_name = f\"Fruit_Classifier_{best_run_name}\"             # \"Fruit_Classifier_Bayesian_26\"\n",
        "\n",
        "# Artifact path (matches how you logged it)\n",
        "model_path_in_run = f\"fruit_classifier_model_{best_run_id}\"\n",
        "\n",
        "# Ensure registered model exists\n",
        "try:\n",
        "    client.get_registered_model(model_name)\n",
        "except MlflowException:\n",
        "    client.create_registered_model(model_name)\n",
        "\n",
        "# Register the version\n",
        "model_version = client.create_model_version(\n",
        "    name=model_name,\n",
        "    source=f\"runs:/{best_run_id}/{model_path_in_run}\",\n",
        "    run_id=best_run_id\n",
        ")\n",
        "\n",
        "# Promote to Staging\n",
        "client.transition_model_version_stage(\n",
        "    name=model_name,\n",
        "    version=model_version.version,\n",
        "    stage=\"Staging\"\n",
        ")\n",
        "\n",
        "print(f\"Model '{model_name}' version {model_version.version} promoted to Staging.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpujrUpZ-JBb"
      },
      "outputs": [],
      "source": [
        "# Optional manual override\n",
        "\"\"\"\n",
        "manual_best_run_id = \"REPLACE_WITH_RUN_ID\"\n",
        "client.transition_model_version_stage(name=model_name, version=model_version.version, stage=\"Archived\")\n",
        "manual_model_version = client.create_model_version(\n",
        "    name=model_name,\n",
        "    source=f\"runs:/{manual_best_run_id}/fruit_classifier_model\",\n",
        "    run_id=manual_best_run_id\n",
        ")\n",
        "client.transition_model_version_stage(name=model_name, version=manual_model_version.version, stage=\"Staging\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrHP6nt4juBf"
      },
      "outputs": [],
      "source": [
        "# Promote to Production (after validating performance, stability, and deployment readiness in Staging.)\n",
        "\n",
        "client.transition_model_version_stage(\n",
        "    name=model_name,\n",
        "    version=model_version.version,\n",
        "    stage=\"Production\"\n",
        ")\n",
        "\n",
        "print(f\"Best model (Run ID: {best_run_id}) is now in Production.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cH_dI3doq41i"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Path to save model\n",
        "save_path = \"/content/best_fruit_model_resnet50v2.h5\"\n",
        "\n",
        "# Save entire model\n",
        "model.save(save_path)\n",
        "print(f\"Model saved at {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPWXs7ieq45E"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNDsJjFxqMHC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3AcapR6I53B"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}